#!/usr/bin/env python3
"""
Vostok - ERA5 Climate Analysis Agent
======================================
An intelligent oceanography and climate data analysis assistant.

Features:
- Persistent memory across sessions
- Cloud-optimized ERA5 data retrieval
- Interactive Python analysis with visualization
- Conversation history and context awareness

Usage:
    python main.py

Commands:
    q, quit, exit  - Exit the agent
    /clear         - Clear conversation history
    /cache         - List cached datasets
    /memory        - Show memory summary
    /cleancache    - Clear Python __pycache__ directories
    /cleardata     - Clear all downloaded ERA5 datasets
    /help          - Show help message
"""

import os
import sys
import logging
from pathlib import Path
from datetime import datetime

from dotenv import load_dotenv

# Configure logging before other imports
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Import after logging is configured
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent

from vostok.config import CONFIG, AGENT_SYSTEM_PROMPT, DATA_DIR, PLOTS_DIR
from vostok.memory import get_memory, MemoryManager
from vostok.tools import get_all_tools


# ============================================================================
# BANNER AND HELP
# ============================================================================

BANNER = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                           â•‘
â•‘    â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—                   â•‘
â•‘    â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•                   â•‘
â•‘    â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•                    â•‘
â•‘    â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•—                    â•‘
â•‘     â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•—                   â•‘
â•‘      â•šâ•â•â•â•   â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•   â•šâ•â•    â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•                   â•‘
â•‘                                                                           â•‘
â•‘                  AI Climate Physicist v2.0                                â•‘
â•‘           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                       â•‘
â•‘                                                                           â•‘
â•‘   Scientific Capabilities:                                                â•‘
â•‘   â€¢ ERA5 reanalysis data retrieval (SST, wind, temperature, pressure)     â•‘
â•‘   â€¢ Climate Diagnostics: Anomalies, Z-Scores, Statistical Significance    â•‘
â•‘   â€¢ Pattern Discovery: EOF/PCA analysis for climate modes                 â•‘
â•‘   â€¢ Compound Extremes: "Ocean Oven" detection (Heat + Stagnation)         â•‘
â•‘   â€¢ Trend Analysis: Decadal trends with p-value significance              â•‘
â•‘   â€¢ Teleconnections: Correlation and lead-lag analysis                    â•‘
â•‘                                                                           â•‘
â•‘   Commands: /help, /clear, /cache, /memory, /quit                         â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

HELP_TEXT = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          VOSTOK HELP - AI Climate Physicist               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                           â•‘
â•‘  COMMANDS:                                                                â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘    /help       - Show this help message                                   â•‘
â•‘    /clear      - Clear conversation history (fresh start)                 â•‘
â•‘    /cache      - List all cached ERA5 datasets                            â•‘
â•‘    /memory     - Show memory summary (datasets, analyses)                 â•‘
â•‘    /cleancache - Clear Python __pycache__ directories                     â•‘
â•‘    /cleardata  - Clear all downloaded ERA5 datasets                       â•‘
â•‘    /quit       - Exit the agent (also: q, quit, exit)                     â•‘
â•‘                                                                           â•‘
â•‘  SCIENTIFIC ANALYSIS (Publication-Grade):                                 â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘    "Analyze marine heatwaves in the North Atlantic summer 2023"           â•‘
â•‘    "Find compound extremes where high SST coincides with low wind"        â•‘
â•‘    "Perform EOF analysis on SST anomalies to find climate modes"          â•‘
â•‘    "Calculate SST trends with statistical significance"                   â•‘
â•‘    "Detect Ocean Ovens in the Mediterranean"                              â•‘
â•‘                                                                           â•‘
â•‘  SCIENCE TOOLS (The "Physics Brain"):                                     â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘    compute_climate_diagnostics  - Z-scores & anomalies (RUN FIRST!)       â•‘
â•‘    analyze_climate_modes_eof    - Pattern discovery via EOF/PCA           â•‘
â•‘    detect_compound_extremes     - "Ocean Oven" detection                  â•‘
â•‘    calculate_climate_trends     - Trends with p-value significance        â•‘
â•‘    calculate_correlation        - Teleconnection analysis                 â•‘
â•‘    detect_percentile_extremes   - Percentile-based extreme detection      â•‘
â•‘    fetch_climate_index          - NOAA indices (Nino3.4, NAO, PDO, AMO)   â•‘
â•‘    calculate_return_periods     - GEV/EVT (1-in-100 year events)          â•‘
â•‘                                                                           â•‘
â•‘  AVAILABLE VARIABLES:                                                     â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘    sst  - Sea Surface Temperature (K)                                     â•‘
â•‘    t2   - 2m Air Temperature (K)                                          â•‘
â•‘    u10  - 10m U-Wind Component (m/s)                                      â•‘
â•‘    v10  - 10m V-Wind Component (m/s)                                      â•‘
â•‘    mslp - Mean Sea Level Pressure (Pa)                                    â•‘
â•‘    tcc  - Total Cloud Cover (0-1)                                         â•‘
â•‘    tp   - Total Precipitation (m)                                         â•‘
â•‘                                                                           â•‘
â•‘  PREDEFINED REGIONS:                                                      â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘    north_atlantic, north_pacific, california_coast, mediterranean         â•‘
â•‘    gulf_of_mexico, caribbean, nino34, nino3, nino4, arctic, antarctic     â•‘
â•‘                                                                           â•‘
â•‘  SCIENTIFIC WORKFLOW:                                                     â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘    1. RETRIEVE data â†’ 2. DIAGNOSE (Z-scores) â†’ 3. DISCOVER (EOF)          â•‘
â•‘    4. DETECT (extremes) â†’ 5. ATTRIBUTE (correlation) â†’ 6. VISUALIZE       â•‘
â•‘                                                                           â•‘
â•‘  TIPS:                                                                    â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘    â€¢ Always report in anomalies/Z-scores, not raw values                  â•‘
â•‘    â€¢ Z > 2Ïƒ means statistically significant extreme                       â•‘
â•‘    â€¢ Use diverging colormaps (RdBu_r) centered at 0 for anomalies         â•‘
â•‘    â€¢ Add stippling for p < 0.05 significance                              â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""


# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

def clear_pycache(root_dir: Path = None) -> tuple[int, int]:
    """
    Remove all __pycache__ directories and .pyc/.pyo files.
    
    Args:
        root_dir: Root directory to search. Defaults to project root.
        
    Returns:
        Tuple of (directories_removed, files_removed)
    """
    import shutil
    
    if root_dir is None:
        root_dir = Path(__file__).parent
    
    dirs_removed = 0
    files_removed = 0
    
    # Find and remove __pycache__ directories
    for cache_dir in root_dir.rglob('__pycache__'):
        if cache_dir.is_dir():
            shutil.rmtree(cache_dir)
            dirs_removed += 1
            logger.debug(f"Removed: {cache_dir}")
    
    # Also remove any stray .pyc/.pyo files
    for pyc_file in root_dir.rglob('*.py[co]'):
        if pyc_file.is_file():
            pyc_file.unlink()
            files_removed += 1
            logger.debug(f"Removed: {pyc_file}")
    
    return dirs_removed, files_removed


def clear_data_directory(data_dir: Path = None) -> tuple[int, float]:
    """
    Remove all downloaded ERA5 datasets (zarr directories) from the data folder.
    
    Args:
        data_dir: Data directory path. Defaults to DATA_DIR from config.
        
    Returns:
        Tuple of (datasets_removed, total_size_mb_freed)
    """
    import shutil
    
    if data_dir is None:
        data_dir = DATA_DIR
    
    datasets_removed = 0
    total_bytes = 0
    
    if not data_dir.exists():
        return 0, 0.0
    
    # Find and remove all .zarr directories
    for zarr_dir in data_dir.glob('*.zarr'):
        if zarr_dir.is_dir():
            # Calculate size before removing
            dir_size = sum(f.stat().st_size for f in zarr_dir.rglob('*') if f.is_file())
            total_bytes += dir_size
            shutil.rmtree(zarr_dir)
            datasets_removed += 1
            logger.debug(f"Removed dataset: {zarr_dir}")
    
    total_mb = total_bytes / (1024 * 1024)
    return datasets_removed, total_mb


# ============================================================================
# COMMAND HANDLERS
# ============================================================================

def handle_command(command: str, memory: MemoryManager) -> tuple[bool, str]:
    """
    Handle slash commands.

    Returns:
        (should_continue, response_message)
    """
    cmd = command.lower().strip()

    if cmd in ('/quit', '/exit', '/q', 'quit', 'exit', 'q'):
        return False, "Goodbye! Your conversation has been saved."

    elif cmd == '/help':
        return True, HELP_TEXT

    elif cmd == '/clear':
        memory.clear_conversation()
        return True, "Conversation history cleared. Starting fresh!"

    elif cmd == '/cache':
        cache_info = memory.list_datasets()
        return True, f"\n{cache_info}\n"

    elif cmd == '/memory':
        summary = memory.get_context_summary()
        datasets = len([p for p in memory.datasets if os.path.exists(p)])
        analyses = len(memory.analyses)
        convos = len(memory.conversations)

        response = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         MEMORY SUMMARY                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Conversation messages: {convos:<5}                                        â•‘
â•‘  Cached datasets: {datasets:<5}                                             â•‘
â•‘  Recorded analyses: {analyses:<5}                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{summary}
"""
        return True, response

    elif cmd == '/cleancache':
        project_root = Path(__file__).parent
        dirs_removed, files_removed = clear_pycache(project_root)
        response = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         CACHE CLEARED                                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  __pycache__ directories removed: {dirs_removed:<5}                                  â•‘
â•‘  .pyc/.pyo files removed: {files_removed:<5}                                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        return True, response

    elif cmd == '/cleardata':
        datasets_removed, size_freed = clear_data_directory(DATA_DIR)
        # Also clear memory references
        memory.datasets.clear()
        memory._save_datasets()
        response = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                       ERA5 DATA CLEARED                                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Datasets removed: {datasets_removed:<5}                                               â•‘
â•‘  Space freed: {size_freed:>8.2f} MB                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        return True, response

    elif cmd.startswith('/'):
        return True, f"Unknown command: {cmd}\nType /help for available commands."

    return True, None  # Not a command


# ============================================================================
# MAIN AGENT LOOP
# ============================================================================

def main():
    """Main entry point for the Vostok agent."""

    # Print banner
    print(BANNER)

    # Check for required API keys
    if not os.environ.get("ARRAYLAKE_API_KEY"):
        print("ERROR: ARRAYLAKE_API_KEY not found in environment.")
        print("Please add it to your .env file:")
        print("  ARRAYLAKE_API_KEY=your_api_key_here")
        sys.exit(1)

    if not os.environ.get("OPENAI_API_KEY"):
        print("ERROR: OPENAI_API_KEY not found in environment.")
        print("Please add it to your .env file:")
        print("  OPENAI_API_KEY=your_api_key_here")
        sys.exit(1)

    # Initialize memory
    print("Initializing memory system...")
    memory = get_memory()

    # Load recent conversation context
    recent_messages = memory.get_langchain_messages(n_messages=10)
    logger.info(f"Loaded {len(recent_messages)} messages from history")

    # Initialize tools
    print("Starting Python kernel...")

    # Ask for extended capabilities
    print("\n" + "-" * 50)
    enable_routing_input = input("Enable Maritime Routing & Risk tools? (Requires scgraph) [y/N]: ").strip().lower()
    enable_routing = enable_routing_input in ('y', 'yes')

    print("\nCapabilities enabled:")
    print("  [âœ“] Data Retrieval (ERA5)")
    print("  [âœ“] Python Analysis (REPL)")
    print("  [âœ“] Climate Science Tools (Diagnostics, EOF, Compound Extremes, Trends)")
    if enable_routing:
        print("  [âœ“] Maritime Routing & Risk")
    else:
        print("  [ ] Maritime Routing & Risk (disabled)")
    print("-" * 50 + "\n")

    tools = get_all_tools(enable_routing=enable_routing, enable_science=True)
    logger.info(f"Loaded {len(tools)} tools")

    # Initialize LLM
    print("Connecting to LLM...")
    llm = ChatOpenAI(
        model=CONFIG.model_name,
        temperature=CONFIG.temperature,
        streaming=True  # Enable streaming for real-time output
    )

    # Create enhanced system prompt with context
    context_summary = memory.get_context_summary()
    enhanced_prompt = AGENT_SYSTEM_PROMPT

    if context_summary and context_summary != "No context available.":
        enhanced_prompt += f"\n\n## CURRENT CONTEXT\n{context_summary}"

    # Create agent
    print("Creating agent...")
    agent = create_agent(
        model=llm,
        tools=tools,
        system_prompt=enhanced_prompt,
        debug=False
    )

    # Initialize messages with history
    messages = recent_messages.copy()

    print("\n" + "=" * 75)
    print("READY! Type your question or /help for commands.")
    print("=" * 75 + "\n")

    # Main interaction loop
    try:
        while True:
            # Get user input
            try:
                user_input = input(">> You: ").strip()
            except EOFError:
                break

            if not user_input:
                continue

            # Handle commands
            should_continue, response = handle_command(user_input, memory)

            if response:
                print(response)

            if not should_continue:
                break

            if response:  # Command was handled, skip agent
                continue

            # Save user message to memory
            memory.add_message("user", user_input)
            messages.append({"role": "user", "content": user_input})

            # Get agent response
            print("\nThinking...\n")

            try:
                # Stream the response for real-time output
                print("\n" + "â”€" * 75)
                
                full_response = ""
                tool_executed = False
                
                for event in agent.stream({"messages": messages}, stream_mode="updates"):
                    # Handle different event types
                    for node_name, node_output in event.items():
                        if node_name == "agent":
                            # LLM is producing output
                            if "messages" in node_output:
                                for msg in node_output["messages"]:
                                    # Check for tool calls
                                    if hasattr(msg, 'tool_calls') and msg.tool_calls:
                                        for tc in msg.tool_calls:
                                            tool_name = tc.get('name', 'unknown')
                                            print(f"ğŸ”§ Calling: {tool_name}...", flush=True)
                                            tool_executed = True
                                    # Check for final content
                                    elif hasattr(msg, 'content') and msg.content:
                                        if not tool_executed:
                                            print("Vostok: ", end="", flush=True)
                                        else:
                                            print("\n\nğŸ“ Response:", flush=True)
                                        print(msg.content, flush=True)
                                        full_response = msg.content
                        
                        elif node_name == "tools":
                            # Tool execution completed
                            if "messages" in node_output:
                                for msg in node_output["messages"]:
                                    if hasattr(msg, 'name'):
                                        print(f"   âœ“ {msg.name} done", flush=True)
                
                print("â”€" * 75 + "\n")
                
                # Update messages for the next turn
                if full_response:
                    messages.append({"role": "assistant", "content": full_response})
                    memory.add_message("assistant", full_response)
                else:
                    # Fallback: use invoke if streaming didn't capture content
                    print("(Processing...)", flush=True)
                    result = agent.invoke({"messages": messages})
                    messages = result["messages"]
                    last_message = messages[-1]
                    
                    if hasattr(last_message, 'content') and last_message.content:
                        response_text = last_message.content
                    elif isinstance(last_message, dict) and last_message.get('content'):
                        response_text = last_message['content']
                    else:
                        response_text = str(last_message)
                    
                    print(f"\nVostok: {response_text}")
                    print("â”€" * 75 + "\n")
                    memory.add_message("assistant", response_text)

            except KeyboardInterrupt:
                print("\n\nInterrupted. Type /quit to exit or continue with a new question.")

            except Exception as e:
                error_msg = f"Error: {str(e)}"
                logger.error(error_msg, exc_info=True)
                print(f"\nError during processing: {error_msg}")
                print("Please try again or rephrase your question.\n")

    except KeyboardInterrupt:
        print("\n\nReceived interrupt signal.")

    finally:
        # Cleanup
        print("\nShutting down...")

        # Clean up missing dataset records
        removed = memory.cleanup_missing_datasets()
        if removed:
            logger.info(f"Cleaned up {removed} missing dataset records")

        print("Session saved. Goodbye!")


# ============================================================================
# ENTRY POINT
# ============================================================================

if __name__ == "__main__":
    main()
